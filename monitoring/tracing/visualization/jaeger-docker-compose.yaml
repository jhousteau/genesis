# Jaeger Distributed Tracing System
# Complete setup with Elasticsearch backend and comprehensive UI

version: '3.8'

services:
  # Elasticsearch for trace storage
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.0
    container_name: jaeger-elasticsearch
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms1g -Xmx1g
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    networks:
      - jaeger-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G

  # Jaeger Collector - receives traces from applications
  jaeger-collector:
    image: jaegertracing/jaeger-collector:1.41
    container_name: jaeger-collector
    ports:
      - "14269:14269"  # Admin port
      - "14268:14268"  # HTTP port for spans
      - "14250:14250"  # gRPC port for spans
      - "9411:9411"    # Zipkin compatible endpoint
    environment:
      - SPAN_STORAGE_TYPE=elasticsearch
      - ES_SERVER_URLS=http://elasticsearch:9200
      - ES_NUM_SHARDS=1
      - ES_NUM_REPLICAS=0
      - LOG_LEVEL=info
      - COLLECTOR_ZIPKIN_HOST_PORT=:9411
    networks:
      - jaeger-network
    depends_on:
      elasticsearch:
        condition: service_healthy
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # Jaeger Query Service - serves the UI and API
  jaeger-query:
    image: jaegertracing/jaeger-query:1.41
    container_name: jaeger-query
    ports:
      - "16686:16686"  # UI and API port
      - "16687:16687"  # Admin port
    environment:
      - SPAN_STORAGE_TYPE=elasticsearch
      - ES_SERVER_URLS=http://elasticsearch:9200
      - LOG_LEVEL=info
      - QUERY_BASE_PATH=/
    networks:
      - jaeger-network
    depends_on:
      - elasticsearch
      - jaeger-collector
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # Jaeger Agent - receives traces from applications and forwards to collector
  jaeger-agent:
    image: jaegertracing/jaeger-agent:1.41
    container_name: jaeger-agent
    ports:
      - "6831:6831/udp"  # Jaeger thrift compact
      - "6832:6832/udp"  # Jaeger thrift binary
      - "14271:14271"    # Admin port
    command:
      - "--collector.host-port=jaeger-collector:14267"
      - "--log-level=info"
    networks:
      - jaeger-network
    depends_on:
      - jaeger-collector
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

  # Jaeger Ingester - consumes from Kafka (optional, for high-volume deployments)
  # jaeger-ingester:
  #   image: jaegertracing/jaeger-ingester:1.41
  #   container_name: jaeger-ingester
  #   environment:
  #     - SPAN_STORAGE_TYPE=elasticsearch
  #     - ES_SERVER_URLS=http://elasticsearch:9200
  #     - KAFKA_CONSUMER_BROKERS=kafka:9092
  #     - KAFKA_CONSUMER_TOPIC=jaeger-spans
  #     - LOG_LEVEL=info
  #   networks:
  #     - jaeger-network
  #   depends_on:
  #     - elasticsearch
  #     - kafka

  # OpenTelemetry Collector for OTLP traces
  otel-collector:
    image: otel/opentelemetry-collector-contrib:0.88.0
    container_name: otel-collector
    command: ["--config=/etc/otel-collector-config.yaml"]
    volumes:
      - ../opentelemetry/collector-config.yaml:/etc/otel-collector-config.yaml
    ports:
      - "4317:4317"   # OTLP gRPC receiver
      - "4318:4318"   # OTLP HTTP receiver
      - "8888:8888"   # Prometheus metrics
      - "13133:13133" # Health check
      - "55679:55679" # zpages
    environment:
      - GCP_PROJECT=${GCP_PROJECT:-universal-platform}
      - ENVIRONMENT=${ENVIRONMENT:-development}
      - JAEGER_ENDPOINT=http://jaeger-collector:14268/api/traces
    networks:
      - jaeger-network
    depends_on:
      - jaeger-collector
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # Grafana for trace visualization and dashboards
  grafana:
    image: grafana/grafana:9.5.0
    container_name: jaeger-grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_INSTALL_PLUGINS=grafana-piechart-panel,grafana-worldmap-panel
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
      - ./grafana/dashboards:/var/lib/grafana/dashboards
    networks:
      - jaeger-network
    depends_on:
      - jaeger-query
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M

  # Prometheus for metrics collection (optional)
  prometheus:
    image: prom/prometheus:v2.40.0
    container_name: jaeger-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--storage.tsdb.retention.time=7d'
      - '--web.enable-lifecycle'
    networks:
      - jaeger-network
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # Alertmanager for trace-based alerting
  alertmanager:
    image: prom/alertmanager:v0.25.0
    container_name: jaeger-alertmanager
    ports:
      - "9093:9093"
    volumes:
      - ./alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--web.external-url=http://localhost:9093'
    networks:
      - jaeger-network
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

networks:
  jaeger-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

volumes:
  elasticsearch_data:
    driver: local
  grafana_data:
    driver: local
  prometheus_data:
    driver: local

# Health check script
# Create a file: docker-compose.override.yml for local development overrides
---
# Example prometheus.yml configuration
# Save as: prometheus/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'jaeger-collector'
    static_configs:
      - targets: ['jaeger-collector:14269']

  - job_name: 'jaeger-query'
    static_configs:
      - targets: ['jaeger-query:16687']

  - job_name: 'otel-collector'
    static_configs:
      - targets: ['otel-collector:8888']

  - job_name: 'elasticsearch'
    static_configs:
      - targets: ['elasticsearch:9200']

---
# Example alertmanager.yml configuration
# Save as: alertmanager/alertmanager.yml
global:
  smtp_smarthost: 'localhost:587'
  smtp_from: 'alerts@universal-platform.com'

route:
  group_by: ['alertname']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'web.hook'

receivers:
- name: 'web.hook'
  webhook_configs:
  - url: 'http://localhost:5001/webhook'

inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'dev', 'instance']
